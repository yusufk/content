<!--
title: Thoughts on AI
date: 2025-02-23
--->
Like most tech professionals, my opinion on AI has swung repeatedly between amazement and disappointment, since the release of ChatGPT. 

No one anticipated that using a model trained on the sum of all human written knowledge, to predict the next sequence of words, would predict a sequence of words that embodies any form of reasoning. Is it all that surprising though? After all, written language is what allows us as humans to relay more than just random thoughts. We use language to establish common thoughts and an understanding of the world around us. We have a *world model* that allows us to navigate the world around us, but so do animals, so language is not involved in that  aspect of our human intelligence, however, language does allow us to share that world model, debate and discuss it and grow our understanding of that world model much further than any individual could. Group-think it turns out, is not all that bad after all.

Like most people, I've been equally amazed and disappointed by some of my interactions with Generative AI by I've shifted somewhat from being intrigued or disappointed by the technology, to simply being in awe of the inspiration behind it, i.e. human intelligence. The amount of intelligence that can be contained within that one selected feature of the human brain, the neuron, is, excuse the pun, mind-boggling, but the realisation that there's still a **lot** more to intelligence that we don't yet understand, embodied in countless other features of the brain, nervous system and even the microbiome.

The role of language and more so written language, and the processes that we undergo to learn to communicate is something we all probably undervalued in terms of intelligence. Like LLM's, humans become more intelligent by building an *understanding* of the nature of the world around us, from our 1st interactions in the womb, through touch, light, sound and every trigger to the nervous system. Pre-programmed with some basics, like crying and chuckling, cause and effect patterns get etched into our brains until at some point, we learn to learn from human interaction. The leap from simple gestures to verbal communication, helps us semantically connect information into a more complex abstraction that is likely a major distinguishing factor between humans and animals.

LLM's are a model of that layer of intelligence. Missing the underlying basis of a world model that biology provides us and probably missing other important dimensions I haven't begun to think about yet. Where does the understanding of cause and effect exist in our biology and the concept of now, and time? Is our understanding of the present a feature of our language-driven intelligence, or more fundamental to our biology?

In a more practical sense, LLM's also give us a hint into how we process thoughts. Particularly, how our own "prompting" can influence the outcome of our thoughts. I've become more deliberate about shutting down negative thoughts as much as possible and even trying prompt techniques on myself: "As are a creative expert at Generative AI and LLM's and you have an opportunity to push the bounds of this technology further by engaging with your coworkers today on the use of Generative AI in solving client challenges that could not have been solved otherwise..."

It also helps explain the behaviour of many so-called experts I come across and the confidence they exude as they generate hallucinations in volume, clearly without any chain-of-thought or deep reasoning. Pure stochastic, ungrounded babble. It helps me appreciate those that instead say, "I don't know, let me do some research and come back to you...". True intelligence can surely distinguish between grounded knowledge and pure inference.

I chose *not* to use Generative AI for this piece, it just didn't feel right to. Also, I have a genuine concern that I'm not sure what I'm trading in exchange for this new technology. Is it my own creativity or skill to convey thoughts into written language? Whatever it is, I hope that it's not our own intelligence. 


