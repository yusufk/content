<!--
title: Thoughts on AI
date: 2025-02-23
--->
Like most tech professionals, my opinions of LLM's as the new frontier in AI, has oscillated between amazement and disappointment, since the release of ChatGPT. 

I doubt there's anyone that could have foreseen that a model trained on the sum of all recorded human knowledge, would be able to produce any form of reasoning, logic or wisdom. However, should it be all that surprising? After all, written language is what we as humans use to capture and relay information, knowledge, reasoning and wisdom. We've used language to establish common thoughts and an understanding of the world around us. We have a established a common *world model* of the universe around us that allows us to extend our personal world model to a societal one. Animals do this also to some extend, but their lack of complex language is likely what holds them back from human-level intelligence. We share, debate and discuss our world models to the point where we don't personally have to experience everything ourselves, but can experience things through the shared stories of others. So why wouldn't any LLM inherit those traits?

I've shifted from being intrigued or disappointed by the technology, to simply being in awe of the inspiration behind it, i.e. human intelligence. The amount of intelligence that can be contained within that one selected feature of the human brain, the neuron, is mind-boggling (excuse the pun), but the realisation that there's still a **lot** more nuance and detail to human intelligence that we haven't yet grasped. Embodied in countless other physical, chemical, electrical and even quantum features of the brain, nervous system and the microbiome.

The role of language and more so, written language, and the processes we've developed to learn to communicate is something we undervalue. Like LLM's, humans can become more intelligent simply by building an *understanding* of the nature of the world around us through interaction and learning. These interactions start within days in the womb, through touch, light, sound and every trigger linked to the nervous system. We're somehow pre-programmed with some basic instincts. What starts with crying and chuckling teaches about a fundamentally important feature of our world; that of cause and effect. The logarithmic leap from simple gestures to verbal communication, helps us connect information into a more complex abstractions like knowledge and wisdom.

LLM's model only a slither of human intelligence. They're missing the key features that would extend to a proper world model, which our biology affords us. How might we instil the same understanding of cause and effect in AI? Is our understanding of time and the present a feature of our language-driven intelligence, or more fundamental to our biology?

In a more practical sense, LLM's also give us a hint into how we process thoughts. Particularly, how our own "prompting" can influence the outcome of our thoughts. I've become more deliberate about shutting down negative thoughts as much as possible and even trying prompt techniques on myself: "As are a creative expert at Generative AI and LLM's and you have an opportunity to push the bounds of this technology further by engaging with your coworkers today on the use of Generative AI in solving client challenges that could not have been solved otherwise..."

It also helps explain the behaviour of many so-called experts I come across and the confidence they exude as they generate hallucinations in volume, clearly without any chain-of-thought or deep reasoning. Pure stochastic, ungrounded babble. It helps me appreciate those that instead say, "I don't know, let me do some research and come back to you...". True intelligence can surely distinguish between grounded knowledge and pure inference.

I chose *not* to use Generative AI for this piece, it just didn't feel right to. Also, I have a genuine concern that I'm not sure what I'm trading in exchange for this new technology. Is it my own creativity or skill to convey thoughts into written language? Whatever it is, I hope that it's not our own intelligence. 

#AI #Humans #Nature 